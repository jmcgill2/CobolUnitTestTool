= Notes

== Convention Over Configuration

Ideally, we want the user to have the flexibility they want to customize as much as possible but the freedom to let the
tool do the hard work if they don't want to.

.Conventions and Customizations
|===
|Activity|Convention|Customizations

|Initializtion
|Always Initialize Everything
|Initialize Nothing; Only initialize specific things; Only exclude specific things from initialization

|Negative Testing
|Always Perform Negative Testing on Everything
|Never perform negative testing; Only perform negative testing sometimes; only perform negative testing on some variables

|In Paragraph Perform Statements
|Stub out and verify the perform has been called
|Include the entire paragraph and perform it; stub out specific activity that occurs when it is called

|Database Calls
|Stub out and verify the database call was made once
|Customize the call by populating the expected output or error return

|File Reads
|Stub out and verify the read was made
|Customize the read statement by populating the expected inputs to test
|===

== Negative Testing

If we generate a map of each data element and give it a unique number, we can generate a negative testing indicator for
every data element.  Then, with each test, we can do negative test validation on every element except those we have
indicated should not be tested.

Negative validation should not be done on
* values we expected to change
* values that redefined values we expected to change (or were part of a group level redefines and we did not want to
take a chance).

This negative testing paragraph will be large.  is there such a thing as too large?  For example, if we have 500 variables
we will be making 500 variable checks.

We may not need to check group variables (or will we to check filler?) so that could limit.  Or perhaps we can use group
variables to minimize the amount of negative checking.

We cannot check filler values directly.

We need to include comments with the indicators and the checks in the negative testing paragraph to make sure that it is
easy to determine where we are checking a variable.

We need an easy way to identify (at least at the group level) if a value that is changed is either a redefines of one or
more values (those cannot be tested) or is itself redefined by one or more values (those cannot be tested either) or both.

We need to know the value of each for initialization so we can set up the correct negative test value to compare against.

== Data Elements

We need to know the redefines of every data element (both what redefines it and what it redefines).

We need to know where in the program these data elements are used

== Initialization

We need to move spaces to all the group elements.  This will help with Filler which cannot be initialized any other way.

We need to understand how all the initializations work so we know what to use to do negative testing with.

The initialization paragraph should move spaces to all group variables and then initialize all group variables.

We may discover this approach does not work in all cases.

For redefines we may have a problem.  We will initialize the group level that is redefined only to start with and see
where that gets us.

=== Knowing What to Initialize and What to Ignore

We may need the ability to ignore certain fields when we initialize because they are part of a redefines and one redefine
is being used to drive the initialization or because the hard coded values should not be modified (e.g. a table of months).

We may need indicators that we set for each variable (how big would this get?) to determine if they should be
checked.  We should Y and N indicators and be able to Universally set them and then tweak individual ones.

We will have two levels at which they could be set:

. The test suite level (all tests)
. The individual test level

We will have to decide whether the individual test level has priority over the test suite level (I'm leaning toward
this approach).

Additionally, we will have to figure out how to set the indicators properly for initialization and negative testing
(See Negative Testing).

== Mocking

=== Mocking Paragraphs

We will mock the following Paragraphs:

. Paragraphs that call other programs
. Paragraphs that execute SQL
. Paragraphs that read and write to files

Mocking these paragraphs could involve the following:

* Hard coding values that mimic the results of a call to a program or database or the reading of a file.
* Counting the number of times a paragraph has been called

=== Mocking Parts of Paragraphs

We will mock the following lines in a paragraph we will otherwise keep whole and run tests against:

.  Calls to other programs
.  Read statements
.  Write statements
.  Exec SQL statements

=== Mocking Calls to a Program

To mock a call to the program we will do one of the following (depending on what mattered for the program):

.  Create a mock paragraph that increments a call to the paragraph
.  Create a mock paragraph that returns values provided by the tester

Multiple calls that return different values will either generate ...

.  Multiple paragraphs that are generated and called only once
.  A single paragraph called but an if statement checking the value in an integer value and return values based on which iteration we were on.
.  A single paragraph called but an if statement checking the value in an integer value and perform a new paragraph that set the key values.

=== Mocking and Working Storage Implications

If we are mocking multiple inputs (as from a read statement, a called program or an sql select statement) we will need
to track which one we are on with a working storage value and populated with a move statement in the testing paragraph.

== The Testing Paragraph

.  Initalize
.  Set input values
.  Set any testing variables to the right values
.. Set any test values for calls, reads, writes or sql statements
.. Set the ignore settings to avoid negative checks on either the values we expect to change or redefines of
        those values.
.  Run the Paragraph
.  Validate the results
..   Check the expected results
..   Validate negative checks
. Report the results

== Test Descriptions

There should be a test name, a short description and a long description.  Only the test name should be required.

The report out should have the test name and the short description if it exists along with the results of the test.

== Code Coverage

Code coverage would be possible but clunky.  The one way to do it that I can think of is to track the original code,
map any code from the test program that came from the original code back to the original code, execute with code coverage
turned on in Xpeditor, read the code coverage output and pull out the lines that were executed from the test program,
use the map to identify from that what executed lines came from the original program and report out on that.

This will still be an approximation.

User should be able to decide whether stubbed out lines (or which stubbed out lines) will be counted for the purposes
of code coverage and which will not.  For example, a call to a paragraph may be considered executed even if you mock
the results of the call but a call to another program or to read a file might not count for purposes of code coverage.

== Reporting Results

Report results should be easily swapped out and highly configurable to enable someone to write to a file, database, etc.

Also configurable should be the output format (JSON, XML) and where the output will go (e.g. SonarQube).

=== Report Format
The report format should allow the user to identify the:

* Program
* Paragraph
* Test Name
* Short Description
* Test Result
* Error Details (if test did not pass)